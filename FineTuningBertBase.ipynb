{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer,AutoModel, BertTokenizer, BertModel\n",
    "from datasets import load_dataset, Dataset\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kapsu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = load_dataset('imdb',split='train')\n",
    "imdb = imdb.shard(8, index=1)\n",
    "imdb.set_format(\"torch\",columns=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(example):\n",
    "    wrds = example['text'].split(' ')\n",
    "    flts = [w for w in wrds if w.lower() not in stop_words]\n",
    "    str = \"\"\n",
    "    \n",
    "    for f in flts:\n",
    "        str+= f+\" \"\n",
    "    \n",
    "    new_one = {'text':str[:-1],'label':example['label']}\n",
    "    return new_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(imdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 3125\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.map(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbb = imdb.train_test_split(test_size=0.2,stratify_by_column='label')\n",
    "imdb_train = imdbb['train']\n",
    "imdb_test = imdbb['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 12\n",
    "TEST_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = imdb_train.shape[0] / TRAIN_BATCH_SIZE\n",
    "tokenized_train_batches = []\n",
    "tokenized_train_batches_y = []\n",
    "\n",
    "for i in range(int(n_train)):\n",
    "    btch = imdb_train['text'][TRAIN_BATCH_SIZE*i : min(TRAIN_BATCH_SIZE*(i+1), imdb_train.shape[0])]\n",
    "    tp = tokenizer.batch_encode_plus(btch,max_length=512, padding='max_length', truncation=True,return_tensors='pt')\n",
    "    tokenized_train_batches.append(tp)\n",
    "    tokenized_train_batches_y.append(imdb_train['label'][TRAIN_BATCH_SIZE*i : min(TRAIN_BATCH_SIZE*(i+1), imdb_train.shape[0])])\n",
    "    \n",
    "    if i % (n_train//10) == 0:\n",
    "        print(f' finished {int((i / (n_train)) * 100)}%')\n",
    "\n",
    "print(len(tokenized_train_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " finished 0%\n",
      " finished 9%\n",
      " finished 19%\n",
      " finished 28%\n",
      " finished 38%\n",
      " finished 48%\n",
      " finished 57%\n",
      " finished 67%\n",
      " finished 76%\n",
      " finished 86%\n",
      " finished 96%\n",
      "156\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "n_test = imdb_test.shape[0] / TEST_BATCH_SIZE\n",
    "\n",
    "tokenized_test_batches = []\n",
    "tokenized_test_batches_y = []\n",
    "\n",
    "for i in range(int(n_test)):\n",
    "    btch = imdb_test['text'][TEST_BATCH_SIZE*i : min(TEST_BATCH_SIZE*(i+1), imdb_test.shape[0])]\n",
    "    tp = tokenizer.batch_encode_plus(btch,max_length=512, padding='max_length', truncation=True,return_tensors='pt')\n",
    "    tokenized_test_batches.append(tp)\n",
    "    tokenized_test_batches_y.append(imdb_test['label'][TEST_BATCH_SIZE*i : min(TEST_BATCH_SIZE*(i+1), imdb_test.shape[0])])\n",
    "    \n",
    "    if i % (n_test//10) == 0:\n",
    "        print(f' finished {int((i / (n_test)) * 100)}%')\n",
    "\n",
    "print(len(tokenized_test_batches))\n",
    "print(len(tokenized_test_batches_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_text_train = tokenizer.batch_encode_plus(imdb_train['text'],max_length=512, padding='max_length', truncation=True,return_tensors='pt')\n",
    "# tokenized_text_train = tokenized_text_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_tensor_test = tokenizer.batch_encode_plus(imdb_test['text'],max_length=512, padding='max_length', truncation=True,return_tensors='pt')\n",
    "# text_tensor_test = text_tensor_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBert(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super(FBert,self).__init__()\n",
    "        self.l1 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.l2 = torch.nn.Dropout(0.2)\n",
    "        self.l3 = torch.nn.Linear(768,64)\n",
    "        self.l4 = torch.nn.Linear(64,1)\n",
    "        self.l5 = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        ids = input['input_ids']\n",
    "        tto = input['token_type_ids']\n",
    "        attn = input['attention_mask']\n",
    "        \n",
    "        _, t = self.l1(ids, attention_mask = attn, token_type_ids = tto, return_dict=False)\n",
    "        # print(f'a1[0] -> {t.size()}')\n",
    "        a2 = self.l2(t)\n",
    "        # print(f'a2 -> {a2.size()}')\n",
    "        a3 = self.l3(a2)\n",
    "        # print(f' a3 -> {a3.size()}')\n",
    "        a4 = self.l4(a3)\n",
    "        # print(f' a4 -> {a4.size()}')\n",
    "        a5 = self.l5(a4)\n",
    "        # print(f' a5 -> {a5.size()}')\n",
    "        a6 = a5.squeeze()\n",
    "        # print(f' a6 -> {a6.size()}')\n",
    "        return a6\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = FBert()\n",
    "my_model = my_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n",
    "optim = torch.optim.Adam(my_model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch=0):\n",
    "    my_model.train()\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for batch, batch_y in zip(tokenized_train_batches, tokenized_train_batches_y):\n",
    "        batch.to(device)\n",
    "        preds = my_model(batch)\n",
    "        \n",
    "        actual = torch.as_tensor(batch_y,device=device,dtype=torch.float)\n",
    "        loss = loss_fn(preds,actual)\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        \n",
    "        if count % 20 == 0:\n",
    "            print(f'onto batch: {count}')\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model = my_model, epoch=0):\n",
    "    \n",
    "    loss_graph = []\n",
    "    losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        my_model.eval()\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for b, b_y in zip(tokenized_test_batches, tokenized_test_batches_y):\n",
    "            b.to(device)\n",
    "            test_pred = my_model(b)\n",
    "            actual_test = torch.as_tensor(b_y,device=device,dtype=torch.float)\n",
    "            ts_ls = loss_fn(test_pred, actual_test)\n",
    "            losses.append(ts_ls)\n",
    "            total_loss += ts_ls\n",
    "            count +=1\n",
    "            print(f'Batch {count}, Test loss: {total_loss/count}')\n",
    "            loss_graph.append(total_loss/count)\n",
    "            \n",
    "        total_loss /= len(tokenized_test_batches)\n",
    "        test_loss[epoch] = total_loss\n",
    "        print(f'Epoch {epoch}, Test loss: {total_loss}')\n",
    "        return total_loss, loss_graph, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(model, epoch=0):\n",
    "    \n",
    "    predicted = []\n",
    "    actual = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        my_model.eval()\n",
    "        \n",
    "        for b, b_y in zip(tokenized_test_batches, tokenized_test_batches_y):\n",
    "            b.to(device)\n",
    "            test_pred = model(b)\n",
    "            predicted.extend(test_pred.cpu().tolist())\n",
    "            actual.extend(b_y.flatten().tolist())\n",
    "\n",
    "\n",
    "        return predicted,actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_one_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(my_model,\"temp1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = torch.load(\"temp1.pth\")\n",
    "nm = nm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_test_batches_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9392, 0.0740, 0.0633, 0.0568], device='cuda:0',\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm(tokenized_test_batches[1].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,a = evaluate_preds(nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624 624\n"
     ]
    }
   ],
   "source": [
    "print(len(p),len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(p))\n",
    "pclass = [1 if x > 0.5 else 0 for x in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(p,a):\n",
    "    ps = precision_score(a,p)\n",
    "    rs = recall_score(a,p)\n",
    "    f1 = f1_score(a,p)\n",
    "    ac = accuracy_score(a,p)\n",
    "    \n",
    "    return ps,rs,f1,ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9201277955271565, 0.9230769230769231, 0.9216, 0.9214743589743589)\n"
     ]
    }
   ],
   "source": [
    "print(calculate_metrics(pclass,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1, Test loss: 0.7024685144424438\n",
      "Batch 2, Test loss: 0.696919858455658\n",
      "Batch 3, Test loss: 0.6922356486320496\n",
      "Batch 4, Test loss: 0.6941789388656616\n",
      "Batch 5, Test loss: 0.6957554221153259\n",
      "Batch 6, Test loss: 0.691014289855957\n",
      "Batch 7, Test loss: 0.6935001611709595\n",
      "Batch 8, Test loss: 0.6951670050621033\n",
      "Batch 9, Test loss: 0.6951091885566711\n",
      "Batch 10, Test loss: 0.6964712142944336\n",
      "Batch 11, Test loss: 0.6939231753349304\n",
      "Batch 12, Test loss: 0.6943578124046326\n",
      "Batch 13, Test loss: 0.6961660385131836\n",
      "Batch 14, Test loss: 0.6964450478553772\n",
      "Batch 15, Test loss: 0.6965811848640442\n",
      "Batch 16, Test loss: 0.6973094344139099\n",
      "Batch 17, Test loss: 0.6980265378952026\n",
      "Batch 18, Test loss: 0.6984477043151855\n",
      "Batch 19, Test loss: 0.6990374326705933\n",
      "Batch 20, Test loss: 0.6989561915397644\n",
      "Batch 21, Test loss: 0.698300838470459\n",
      "Batch 22, Test loss: 0.6986575722694397\n",
      "Batch 23, Test loss: 0.6996200680732727\n",
      "Batch 24, Test loss: 0.699577808380127\n",
      "Batch 25, Test loss: 0.699425995349884\n",
      "Batch 26, Test loss: 0.6994903087615967\n",
      "Batch 27, Test loss: 0.6987150311470032\n",
      "Batch 28, Test loss: 0.6987797617912292\n",
      "Batch 29, Test loss: 0.6991435289382935\n",
      "Batch 30, Test loss: 0.6977506279945374\n",
      "Batch 31, Test loss: 0.6982393264770508\n",
      "Batch 32, Test loss: 0.6979772448539734\n",
      "Batch 33, Test loss: 0.6969892382621765\n",
      "Batch 34, Test loss: 0.697012186050415\n",
      "Batch 35, Test loss: 0.6965686082839966\n",
      "Batch 36, Test loss: 0.6968176960945129\n",
      "Batch 37, Test loss: 0.6969497799873352\n",
      "Batch 38, Test loss: 0.6966232657432556\n",
      "Batch 39, Test loss: 0.696613609790802\n",
      "Batch 40, Test loss: 0.6971191167831421\n",
      "Batch 41, Test loss: 0.6977331042289734\n",
      "Batch 42, Test loss: 0.6978625059127808\n",
      "Batch 43, Test loss: 0.6979072690010071\n",
      "Batch 44, Test loss: 0.6985455751419067\n",
      "Batch 45, Test loss: 0.6983703970909119\n",
      "Batch 46, Test loss: 0.6980891823768616\n",
      "Batch 47, Test loss: 0.6984922289848328\n",
      "Batch 48, Test loss: 0.6987230777740479\n",
      "Batch 49, Test loss: 0.6984794735908508\n",
      "Batch 50, Test loss: 0.698375940322876\n",
      "Batch 51, Test loss: 0.6982502341270447\n",
      "Batch 52, Test loss: 0.6984169483184814\n",
      "Batch 53, Test loss: 0.698028028011322\n",
      "Batch 54, Test loss: 0.6977522373199463\n",
      "Batch 55, Test loss: 0.6977252960205078\n",
      "Batch 56, Test loss: 0.6973453164100647\n",
      "Batch 57, Test loss: 0.6969149708747864\n",
      "Batch 58, Test loss: 0.6968733668327332\n",
      "Batch 59, Test loss: 0.6967015266418457\n",
      "Batch 60, Test loss: 0.6968714594841003\n",
      "Batch 61, Test loss: 0.6971198320388794\n",
      "Batch 62, Test loss: 0.6977919936180115\n",
      "Batch 63, Test loss: 0.6977837085723877\n",
      "Batch 64, Test loss: 0.6976202130317688\n",
      "Batch 65, Test loss: 0.6976940035820007\n",
      "Batch 66, Test loss: 0.6974998712539673\n",
      "Batch 67, Test loss: 0.697476863861084\n",
      "Batch 68, Test loss: 0.69759601354599\n",
      "Batch 69, Test loss: 0.6972710490226746\n",
      "Batch 70, Test loss: 0.6970323920249939\n",
      "Batch 71, Test loss: 0.6968892812728882\n",
      "Batch 72, Test loss: 0.6973381638526917\n",
      "Batch 73, Test loss: 0.6971752047538757\n",
      "Batch 74, Test loss: 0.6973105669021606\n",
      "Batch 75, Test loss: 0.6970813870429993\n",
      "Batch 76, Test loss: 0.6969970464706421\n",
      "Batch 77, Test loss: 0.6970292329788208\n",
      "Batch 78, Test loss: 0.6970425844192505\n",
      "Batch 79, Test loss: 0.6969066858291626\n",
      "Batch 80, Test loss: 0.6966928839683533\n",
      "Batch 81, Test loss: 0.6965875625610352\n",
      "Batch 82, Test loss: 0.6964099407196045\n",
      "Batch 83, Test loss: 0.696303129196167\n",
      "Batch 84, Test loss: 0.6962201595306396\n",
      "Batch 85, Test loss: 0.6961207389831543\n",
      "Batch 86, Test loss: 0.6961174607276917\n",
      "Batch 87, Test loss: 0.6960405707359314\n",
      "Batch 88, Test loss: 0.6961079239845276\n",
      "Batch 89, Test loss: 0.6961348056793213\n",
      "Batch 90, Test loss: 0.6960411071777344\n",
      "Batch 91, Test loss: 0.6961984634399414\n",
      "Batch 92, Test loss: 0.6958325505256653\n",
      "Batch 93, Test loss: 0.695810079574585\n",
      "Batch 94, Test loss: 0.695645272731781\n",
      "Batch 95, Test loss: 0.6954381465911865\n",
      "Batch 96, Test loss: 0.6955134868621826\n",
      "Batch 97, Test loss: 0.6954542994499207\n",
      "Batch 98, Test loss: 0.6956382989883423\n",
      "Batch 99, Test loss: 0.6957843899726868\n",
      "Batch 100, Test loss: 0.6957757472991943\n",
      "Batch 101, Test loss: 0.6958816051483154\n",
      "Batch 102, Test loss: 0.6956334710121155\n",
      "Batch 103, Test loss: 0.6954779624938965\n",
      "Batch 104, Test loss: 0.6956790089607239\n",
      "Batch 105, Test loss: 0.69551682472229\n",
      "Batch 106, Test loss: 0.69536954164505\n",
      "Batch 107, Test loss: 0.6955257654190063\n",
      "Batch 108, Test loss: 0.6954696774482727\n",
      "Batch 109, Test loss: 0.6954240202903748\n",
      "Batch 110, Test loss: 0.6951991319656372\n",
      "Batch 111, Test loss: 0.6953033804893494\n",
      "Batch 112, Test loss: 0.6952930092811584\n",
      "Batch 113, Test loss: 0.6951183080673218\n",
      "Batch 114, Test loss: 0.6949568390846252\n",
      "Batch 115, Test loss: 0.694942831993103\n",
      "Batch 116, Test loss: 0.6950411796569824\n",
      "Batch 117, Test loss: 0.6950128078460693\n",
      "Batch 118, Test loss: 0.6949465274810791\n",
      "Batch 119, Test loss: 0.6949520111083984\n",
      "Batch 120, Test loss: 0.6947843432426453\n",
      "Batch 121, Test loss: 0.6946566104888916\n",
      "Batch 122, Test loss: 0.6946828365325928\n",
      "Batch 123, Test loss: 0.6947672963142395\n",
      "Batch 124, Test loss: 0.6948042511940002\n",
      "Batch 125, Test loss: 0.6947290897369385\n",
      "Batch 126, Test loss: 0.6948666572570801\n",
      "Batch 127, Test loss: 0.6949155926704407\n",
      "Batch 128, Test loss: 0.6950342655181885\n",
      "Batch 129, Test loss: 0.695111870765686\n",
      "Batch 130, Test loss: 0.6950070261955261\n",
      "Batch 131, Test loss: 0.6952587366104126\n",
      "Batch 132, Test loss: 0.6951891779899597\n",
      "Batch 133, Test loss: 0.6953142881393433\n",
      "Batch 134, Test loss: 0.6954293251037598\n",
      "Batch 135, Test loss: 0.695428192615509\n",
      "Batch 136, Test loss: 0.6955325603485107\n",
      "Batch 137, Test loss: 0.6954179406166077\n",
      "Batch 138, Test loss: 0.6955334544181824\n",
      "Batch 139, Test loss: 0.6953992247581482\n",
      "Batch 140, Test loss: 0.695466935634613\n",
      "Batch 141, Test loss: 0.6953960657119751\n",
      "Batch 142, Test loss: 0.6954483389854431\n",
      "Batch 143, Test loss: 0.6954459547996521\n",
      "Batch 144, Test loss: 0.6955392956733704\n",
      "Batch 145, Test loss: 0.6956733465194702\n",
      "Batch 146, Test loss: 0.6956888437271118\n",
      "Batch 147, Test loss: 0.6959295868873596\n",
      "Batch 148, Test loss: 0.6958287954330444\n",
      "Batch 149, Test loss: 0.6958029270172119\n",
      "Batch 150, Test loss: 0.6958613991737366\n",
      "Batch 151, Test loss: 0.6957866549491882\n",
      "Batch 152, Test loss: 0.6957961320877075\n",
      "Batch 153, Test loss: 0.6957243084907532\n",
      "Batch 154, Test loss: 0.695650577545166\n",
      "Batch 155, Test loss: 0.6957937479019165\n",
      "Batch 156, Test loss: 0.6959500312805176\n",
      "Epoch 0, Test loss: 0.6959500312805176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.6960, device='cuda:0'),\n",
       " [tensor(0.7025, device='cuda:0'),\n",
       "  tensor(0.6969, device='cuda:0'),\n",
       "  tensor(0.6922, device='cuda:0'),\n",
       "  tensor(0.6942, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.6910, device='cuda:0'),\n",
       "  tensor(0.6935, device='cuda:0'),\n",
       "  tensor(0.6952, device='cuda:0'),\n",
       "  tensor(0.6951, device='cuda:0'),\n",
       "  tensor(0.6965, device='cuda:0'),\n",
       "  tensor(0.6939, device='cuda:0'),\n",
       "  tensor(0.6944, device='cuda:0'),\n",
       "  tensor(0.6962, device='cuda:0'),\n",
       "  tensor(0.6964, device='cuda:0'),\n",
       "  tensor(0.6966, device='cuda:0'),\n",
       "  tensor(0.6973, device='cuda:0'),\n",
       "  tensor(0.6980, device='cuda:0'),\n",
       "  tensor(0.6984, device='cuda:0'),\n",
       "  tensor(0.6990, device='cuda:0'),\n",
       "  tensor(0.6990, device='cuda:0'),\n",
       "  tensor(0.6983, device='cuda:0'),\n",
       "  tensor(0.6987, device='cuda:0'),\n",
       "  tensor(0.6996, device='cuda:0'),\n",
       "  tensor(0.6996, device='cuda:0'),\n",
       "  tensor(0.6994, device='cuda:0'),\n",
       "  tensor(0.6995, device='cuda:0'),\n",
       "  tensor(0.6987, device='cuda:0'),\n",
       "  tensor(0.6988, device='cuda:0'),\n",
       "  tensor(0.6991, device='cuda:0'),\n",
       "  tensor(0.6978, device='cuda:0'),\n",
       "  tensor(0.6982, device='cuda:0'),\n",
       "  tensor(0.6980, device='cuda:0'),\n",
       "  tensor(0.6970, device='cuda:0'),\n",
       "  tensor(0.6970, device='cuda:0'),\n",
       "  tensor(0.6966, device='cuda:0'),\n",
       "  tensor(0.6968, device='cuda:0'),\n",
       "  tensor(0.6969, device='cuda:0'),\n",
       "  tensor(0.6966, device='cuda:0'),\n",
       "  tensor(0.6966, device='cuda:0'),\n",
       "  tensor(0.6971, device='cuda:0'),\n",
       "  tensor(0.6977, device='cuda:0'),\n",
       "  tensor(0.6979, device='cuda:0'),\n",
       "  tensor(0.6979, device='cuda:0'),\n",
       "  tensor(0.6985, device='cuda:0'),\n",
       "  tensor(0.6984, device='cuda:0'),\n",
       "  tensor(0.6981, device='cuda:0'),\n",
       "  tensor(0.6985, device='cuda:0'),\n",
       "  tensor(0.6987, device='cuda:0'),\n",
       "  tensor(0.6985, device='cuda:0'),\n",
       "  tensor(0.6984, device='cuda:0'),\n",
       "  tensor(0.6983, device='cuda:0'),\n",
       "  tensor(0.6984, device='cuda:0'),\n",
       "  tensor(0.6980, device='cuda:0'),\n",
       "  tensor(0.6978, device='cuda:0'),\n",
       "  tensor(0.6977, device='cuda:0'),\n",
       "  tensor(0.6973, device='cuda:0'),\n",
       "  tensor(0.6969, device='cuda:0'),\n",
       "  tensor(0.6969, device='cuda:0'),\n",
       "  tensor(0.6967, device='cuda:0'),\n",
       "  tensor(0.6969, device='cuda:0'),\n",
       "  tensor(0.6971, device='cuda:0'),\n",
       "  tensor(0.6978, device='cuda:0'),\n",
       "  tensor(0.6978, device='cuda:0'),\n",
       "  tensor(0.6976, device='cuda:0'),\n",
       "  tensor(0.6977, device='cuda:0'),\n",
       "  tensor(0.6975, device='cuda:0'),\n",
       "  tensor(0.6975, device='cuda:0'),\n",
       "  tensor(0.6976, device='cuda:0'),\n",
       "  tensor(0.6973, device='cuda:0'),\n",
       "  tensor(0.6970, device='cuda:0'),\n",
       "  tensor(0.6969, device='cuda:0'),\n",
       "  tensor(0.6973, device='cuda:0'),\n",
       "  tensor(0.6972, device='cuda:0'),\n",
       "  tensor(0.6973, device='cuda:0'),\n",
       "  tensor(0.6971, device='cuda:0'),\n",
       "  tensor(0.6970, device='cuda:0'),\n",
       "  tensor(0.6970, device='cuda:0'),\n",
       "  tensor(0.6970, device='cuda:0'),\n",
       "  tensor(0.6969, device='cuda:0'),\n",
       "  tensor(0.6967, device='cuda:0'),\n",
       "  tensor(0.6966, device='cuda:0'),\n",
       "  tensor(0.6964, device='cuda:0'),\n",
       "  tensor(0.6963, device='cuda:0'),\n",
       "  tensor(0.6962, device='cuda:0'),\n",
       "  tensor(0.6961, device='cuda:0'),\n",
       "  tensor(0.6961, device='cuda:0'),\n",
       "  tensor(0.6960, device='cuda:0'),\n",
       "  tensor(0.6961, device='cuda:0'),\n",
       "  tensor(0.6961, device='cuda:0'),\n",
       "  tensor(0.6960, device='cuda:0'),\n",
       "  tensor(0.6962, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.6956, device='cuda:0'),\n",
       "  tensor(0.6954, device='cuda:0'),\n",
       "  tensor(0.6955, device='cuda:0'),\n",
       "  tensor(0.6955, device='cuda:0'),\n",
       "  tensor(0.6956, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.6959, device='cuda:0'),\n",
       "  tensor(0.6956, device='cuda:0'),\n",
       "  tensor(0.6955, device='cuda:0'),\n",
       "  tensor(0.6957, device='cuda:0'),\n",
       "  tensor(0.6955, device='cuda:0'),\n",
       "  tensor(0.6954, device='cuda:0'),\n",
       "  tensor(0.6955, device='cuda:0'),\n",
       "  tensor(0.6955, device='cuda:0'),\n",
       "  tensor(0.6954, device='cuda:0'),\n",
       "  tensor(0.6952, device='cuda:0'),\n",
       "  tensor(0.6953, device='cuda:0'),\n",
       "  tensor(0.6953, device='cuda:0'),\n",
       "  tensor(0.6951, device='cuda:0'),\n",
       "  tensor(0.6950, device='cuda:0'),\n",
       "  tensor(0.6949, device='cuda:0'),\n",
       "  tensor(0.6950, device='cuda:0'),\n",
       "  tensor(0.6950, device='cuda:0'),\n",
       "  tensor(0.6949, device='cuda:0'),\n",
       "  tensor(0.6950, device='cuda:0'),\n",
       "  tensor(0.6948, device='cuda:0'),\n",
       "  tensor(0.6947, device='cuda:0'),\n",
       "  tensor(0.6947, device='cuda:0'),\n",
       "  tensor(0.6948, device='cuda:0'),\n",
       "  tensor(0.6948, device='cuda:0'),\n",
       "  tensor(0.6947, device='cuda:0'),\n",
       "  tensor(0.6949, device='cuda:0'),\n",
       "  tensor(0.6949, device='cuda:0'),\n",
       "  tensor(0.6950, device='cuda:0'),\n",
       "  tensor(0.6951, device='cuda:0'),\n",
       "  tensor(0.6950, device='cuda:0'),\n",
       "  tensor(0.6953, device='cuda:0'),\n",
       "  tensor(0.6952, device='cuda:0'),\n",
       "  tensor(0.6953, device='cuda:0'),\n",
       "  tensor(0.6954, device='cuda:0'),\n",
       "  tensor(0.6954, device='cuda:0'),\n",
       "  tensor(0.6955, device='cuda:0'),\n",
       "  tensor(0.6954, device='cuda:0'),\n",
       "  tensor(0.6955, device='cuda:0'),\n",
       "  tensor(0.6954, device='cuda:0'),\n",
       "  tensor(0.6955, device='cuda:0'),\n",
       "  tensor(0.6954, device='cuda:0'),\n",
       "  tensor(0.6954, device='cuda:0'),\n",
       "  tensor(0.6954, device='cuda:0'),\n",
       "  tensor(0.6955, device='cuda:0'),\n",
       "  tensor(0.6957, device='cuda:0'),\n",
       "  tensor(0.6957, device='cuda:0'),\n",
       "  tensor(0.6959, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.6959, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.6957, device='cuda:0'),\n",
       "  tensor(0.6957, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.6960, device='cuda:0')],\n",
       " [tensor(0.7025, device='cuda:0'),\n",
       "  tensor(0.6914, device='cuda:0'),\n",
       "  tensor(0.6829, device='cuda:0'),\n",
       "  tensor(0.7000, device='cuda:0'),\n",
       "  tensor(0.7021, device='cuda:0'),\n",
       "  tensor(0.6673, device='cuda:0'),\n",
       "  tensor(0.7084, device='cuda:0'),\n",
       "  tensor(0.7068, device='cuda:0'),\n",
       "  tensor(0.6946, device='cuda:0'),\n",
       "  tensor(0.7087, device='cuda:0'),\n",
       "  tensor(0.6684, device='cuda:0'),\n",
       "  tensor(0.6991, device='cuda:0'),\n",
       "  tensor(0.7179, device='cuda:0'),\n",
       "  tensor(0.7001, device='cuda:0'),\n",
       "  tensor(0.6985, device='cuda:0'),\n",
       "  tensor(0.7082, device='cuda:0'),\n",
       "  tensor(0.7095, device='cuda:0'),\n",
       "  tensor(0.7056, device='cuda:0'),\n",
       "  tensor(0.7097, device='cuda:0'),\n",
       "  tensor(0.6974, device='cuda:0'),\n",
       "  tensor(0.6852, device='cuda:0'),\n",
       "  tensor(0.7061, device='cuda:0'),\n",
       "  tensor(0.7208, device='cuda:0'),\n",
       "  tensor(0.6986, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.7011, device='cuda:0'),\n",
       "  tensor(0.6786, device='cuda:0'),\n",
       "  tensor(0.7005, device='cuda:0'),\n",
       "  tensor(0.7093, device='cuda:0'),\n",
       "  tensor(0.6574, device='cuda:0'),\n",
       "  tensor(0.7129, device='cuda:0'),\n",
       "  tensor(0.6899, device='cuda:0'),\n",
       "  tensor(0.6654, device='cuda:0'),\n",
       "  tensor(0.6978, device='cuda:0'),\n",
       "  tensor(0.6815, device='cuda:0'),\n",
       "  tensor(0.7055, device='cuda:0'),\n",
       "  tensor(0.7017, device='cuda:0'),\n",
       "  tensor(0.6845, device='cuda:0'),\n",
       "  tensor(0.6962, device='cuda:0'),\n",
       "  tensor(0.7168, device='cuda:0'),\n",
       "  tensor(0.7223, device='cuda:0'),\n",
       "  tensor(0.7032, device='cuda:0'),\n",
       "  tensor(0.6998, device='cuda:0'),\n",
       "  tensor(0.7260, device='cuda:0'),\n",
       "  tensor(0.6907, device='cuda:0'),\n",
       "  tensor(0.6854, device='cuda:0'),\n",
       "  tensor(0.7170, device='cuda:0'),\n",
       "  tensor(0.7096, device='cuda:0'),\n",
       "  tensor(0.6868, device='cuda:0'),\n",
       "  tensor(0.6933, device='cuda:0'),\n",
       "  tensor(0.6920, device='cuda:0'),\n",
       "  tensor(0.7069, device='cuda:0'),\n",
       "  tensor(0.6778, device='cuda:0'),\n",
       "  tensor(0.6831, device='cuda:0'),\n",
       "  tensor(0.6963, device='cuda:0'),\n",
       "  tensor(0.6764, device='cuda:0'),\n",
       "  tensor(0.6728, device='cuda:0'),\n",
       "  tensor(0.6945, device='cuda:0'),\n",
       "  tensor(0.6867, device='cuda:0'),\n",
       "  tensor(0.7069, device='cuda:0'),\n",
       "  tensor(0.7120, device='cuda:0'),\n",
       "  tensor(0.7388, device='cuda:0'),\n",
       "  tensor(0.6973, device='cuda:0'),\n",
       "  tensor(0.6873, device='cuda:0'),\n",
       "  tensor(0.7024, device='cuda:0'),\n",
       "  tensor(0.6849, device='cuda:0'),\n",
       "  tensor(0.6960, device='cuda:0'),\n",
       "  tensor(0.7056, device='cuda:0'),\n",
       "  tensor(0.6752, device='cuda:0'),\n",
       "  tensor(0.6806, device='cuda:0'),\n",
       "  tensor(0.6869, device='cuda:0'),\n",
       "  tensor(0.7292, device='cuda:0'),\n",
       "  tensor(0.6854, device='cuda:0'),\n",
       "  tensor(0.7072, device='cuda:0'),\n",
       "  tensor(0.6801, device='cuda:0'),\n",
       "  tensor(0.6907, device='cuda:0'),\n",
       "  tensor(0.6995, device='cuda:0'),\n",
       "  tensor(0.6981, device='cuda:0'),\n",
       "  tensor(0.6863, device='cuda:0'),\n",
       "  tensor(0.6798, device='cuda:0'),\n",
       "  tensor(0.6882, device='cuda:0'),\n",
       "  tensor(0.6820, device='cuda:0'),\n",
       "  tensor(0.6875, device='cuda:0'),\n",
       "  tensor(0.6893, device='cuda:0'),\n",
       "  tensor(0.6878, device='cuda:0'),\n",
       "  tensor(0.6958, device='cuda:0'),\n",
       "  tensor(0.6894, device='cuda:0'),\n",
       "  tensor(0.7020, device='cuda:0'),\n",
       "  tensor(0.6985, device='cuda:0'),\n",
       "  tensor(0.6877, device='cuda:0'),\n",
       "  tensor(0.7104, device='cuda:0'),\n",
       "  tensor(0.6625, device='cuda:0'),\n",
       "  tensor(0.6937, device='cuda:0'),\n",
       "  tensor(0.6803, device='cuda:0'),\n",
       "  tensor(0.6760, device='cuda:0'),\n",
       "  tensor(0.7027, device='cuda:0'),\n",
       "  tensor(0.6898, device='cuda:0'),\n",
       "  tensor(0.7135, device='cuda:0'),\n",
       "  tensor(0.7101, device='cuda:0'),\n",
       "  tensor(0.6949, device='cuda:0'),\n",
       "  tensor(0.7065, device='cuda:0'),\n",
       "  tensor(0.6706, device='cuda:0'),\n",
       "  tensor(0.6796, device='cuda:0'),\n",
       "  tensor(0.7164, device='cuda:0'),\n",
       "  tensor(0.6787, device='cuda:0'),\n",
       "  tensor(0.6799, device='cuda:0'),\n",
       "  tensor(0.7121, device='cuda:0'),\n",
       "  tensor(0.6895, device='cuda:0'),\n",
       "  tensor(0.6905, device='cuda:0'),\n",
       "  tensor(0.6707, device='cuda:0'),\n",
       "  tensor(0.7068, device='cuda:0'),\n",
       "  tensor(0.6941, device='cuda:0'),\n",
       "  tensor(0.6756, device='cuda:0'),\n",
       "  tensor(0.6767, device='cuda:0'),\n",
       "  tensor(0.6933, device='cuda:0'),\n",
       "  tensor(0.7064, device='cuda:0'),\n",
       "  tensor(0.6917, device='cuda:0'),\n",
       "  tensor(0.6872, device='cuda:0'),\n",
       "  tensor(0.6956, device='cuda:0'),\n",
       "  tensor(0.6748, device='cuda:0'),\n",
       "  tensor(0.6793, device='cuda:0'),\n",
       "  tensor(0.6979, device='cuda:0'),\n",
       "  tensor(0.7051, device='cuda:0'),\n",
       "  tensor(0.6994, device='cuda:0'),\n",
       "  tensor(0.6854, device='cuda:0'),\n",
       "  tensor(0.7121, device='cuda:0'),\n",
       "  tensor(0.7011, device='cuda:0'),\n",
       "  tensor(0.7101, device='cuda:0'),\n",
       "  tensor(0.7050, device='cuda:0'),\n",
       "  tensor(0.6815, device='cuda:0'),\n",
       "  tensor(0.7280, device='cuda:0'),\n",
       "  tensor(0.6861, device='cuda:0'),\n",
       "  tensor(0.7118, device='cuda:0'),\n",
       "  tensor(0.7107, device='cuda:0'),\n",
       "  tensor(0.6953, device='cuda:0'),\n",
       "  tensor(0.7096, device='cuda:0'),\n",
       "  tensor(0.6798, device='cuda:0'),\n",
       "  tensor(0.7114, device='cuda:0'),\n",
       "  tensor(0.6769, device='cuda:0'),\n",
       "  tensor(0.7049, device='cuda:0'),\n",
       "  tensor(0.6855, device='cuda:0'),\n",
       "  tensor(0.7028, device='cuda:0'),\n",
       "  tensor(0.6951, device='cuda:0'),\n",
       "  tensor(0.7089, device='cuda:0'),\n",
       "  tensor(0.7150, device='cuda:0'),\n",
       "  tensor(0.6979, device='cuda:0'),\n",
       "  tensor(0.7311, device='cuda:0'),\n",
       "  tensor(0.6810, device='cuda:0'),\n",
       "  tensor(0.6920, device='cuda:0'),\n",
       "  tensor(0.7046, device='cuda:0'),\n",
       "  tensor(0.6846, device='cuda:0'),\n",
       "  tensor(0.6972, device='cuda:0'),\n",
       "  tensor(0.6848, device='cuda:0'),\n",
       "  tensor(0.6844, device='cuda:0'),\n",
       "  tensor(0.7178, device='cuda:0'),\n",
       "  tensor(0.7202, device='cuda:0')])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model = nm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlprep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
